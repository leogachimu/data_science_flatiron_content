{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating PCA in Pipelines - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a previous section, you learned about how to use pipelines in scikit-learn to combine several supervised learning algorithms in a manageable pipeline. In this lesson, you will integrate PCA along with classifiers in the pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "In this lab you will: \n",
    "\n",
    "- Integrate PCA in scikit-learn pipelines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data Science Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be following the data science workflow:\n",
    "\n",
    "1. Initial data inspection, exploratory data analysis, and cleaning\n",
    "2. Feature engineering and selection\n",
    "3. Create a baseline model\n",
    "4. Create a machine learning pipeline and compare results with the baseline model\n",
    "5. Interpret the model and draw conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Initial data inspection, exploratory data analysis, and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll use a dataset created by the Otto group, which was also used in a [Kaggle competition](https://www.kaggle.com/c/otto-group-product-classification-challenge/data). The description of the dataset is as follows:\n",
    "\n",
    "The Otto Group is one of the world’s biggest e-commerce companies, with subsidiaries in more than 20 countries, including Crate & Barrel (USA), Otto.de (Germany) and 3 Suisses (France). They are selling millions of products worldwide every day, with several thousand products being added to their product line.\n",
    "\n",
    "A consistent analysis of the performance of their products is crucial. However, due to their global infrastructure, many identical products get classified differently. Therefore, the quality of product analysis depends heavily on the ability to accurately cluster similar products. The better the classification, the more insights the Otto Group can generate about their product range.\n",
    "\n",
    "In this lab, you'll use a dataset containing:\n",
    "- A column `id`, which is an anonymous id unique to a product\n",
    "- 93 columns `feat_1`, `feat_2`, ..., `feat_93`, which are the various features of a product\n",
    "- a column `target` - the class of a product\n",
    "\n",
    "\n",
    "\n",
    "The dataset is stored in the `'otto_group.csv'` file. Import this file into a DataFrame called `data`, and then: \n",
    "\n",
    "- Check for missing values \n",
    "- Check the distribution of columns \n",
    "- ... and any other things that come to your mind to explore the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
       "id                                                                           \n",
       "1        1       0       0       0       0       0       0       0       0   \n",
       "2        0       0       0       0       0       0       0       1       0   \n",
       "3        0       0       0       0       0       0       0       1       0   \n",
       "4        1       0       0       1       6       1       5       0       0   \n",
       "5        0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "    feat_10  ...  feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  \\\n",
       "id           ...                                                         \n",
       "1         0  ...        1        0        0        0        0        0   \n",
       "2         0  ...        0        0        0        0        0        0   \n",
       "3         0  ...        0        0        0        0        0        0   \n",
       "4         1  ...        0        1        2        0        0        0   \n",
       "5         0  ...        1        0        0        0        0        1   \n",
       "\n",
       "    feat_91  feat_92  feat_93   target  \n",
       "id                                      \n",
       "1         0        0        0  Class_1  \n",
       "2         0        0        0  Class_1  \n",
       "3         0        0        0  Class_1  \n",
       "4         0        0        0  Class_1  \n",
       "5         0        0        0  Class_1  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('otto_group.csv', index_col='id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 61878 entries, 0 to 61877\n",
      "Data columns (total 95 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   id       61878 non-null  int64 \n",
      " 1   feat_1   61878 non-null  int64 \n",
      " 2   feat_2   61878 non-null  int64 \n",
      " 3   feat_3   61878 non-null  int64 \n",
      " 4   feat_4   61878 non-null  int64 \n",
      " 5   feat_5   61878 non-null  int64 \n",
      " 6   feat_6   61878 non-null  int64 \n",
      " 7   feat_7   61878 non-null  int64 \n",
      " 8   feat_8   61878 non-null  int64 \n",
      " 9   feat_9   61878 non-null  int64 \n",
      " 10  feat_10  61878 non-null  int64 \n",
      " 11  feat_11  61878 non-null  int64 \n",
      " 12  feat_12  61878 non-null  int64 \n",
      " 13  feat_13  61878 non-null  int64 \n",
      " 14  feat_14  61878 non-null  int64 \n",
      " 15  feat_15  61878 non-null  int64 \n",
      " 16  feat_16  61878 non-null  int64 \n",
      " 17  feat_17  61878 non-null  int64 \n",
      " 18  feat_18  61878 non-null  int64 \n",
      " 19  feat_19  61878 non-null  int64 \n",
      " 20  feat_20  61878 non-null  int64 \n",
      " 21  feat_21  61878 non-null  int64 \n",
      " 22  feat_22  61878 non-null  int64 \n",
      " 23  feat_23  61878 non-null  int64 \n",
      " 24  feat_24  61878 non-null  int64 \n",
      " 25  feat_25  61878 non-null  int64 \n",
      " 26  feat_26  61878 non-null  int64 \n",
      " 27  feat_27  61878 non-null  int64 \n",
      " 28  feat_28  61878 non-null  int64 \n",
      " 29  feat_29  61878 non-null  int64 \n",
      " 30  feat_30  61878 non-null  int64 \n",
      " 31  feat_31  61878 non-null  int64 \n",
      " 32  feat_32  61878 non-null  int64 \n",
      " 33  feat_33  61878 non-null  int64 \n",
      " 34  feat_34  61878 non-null  int64 \n",
      " 35  feat_35  61878 non-null  int64 \n",
      " 36  feat_36  61878 non-null  int64 \n",
      " 37  feat_37  61878 non-null  int64 \n",
      " 38  feat_38  61878 non-null  int64 \n",
      " 39  feat_39  61878 non-null  int64 \n",
      " 40  feat_40  61878 non-null  int64 \n",
      " 41  feat_41  61878 non-null  int64 \n",
      " 42  feat_42  61878 non-null  int64 \n",
      " 43  feat_43  61878 non-null  int64 \n",
      " 44  feat_44  61878 non-null  int64 \n",
      " 45  feat_45  61878 non-null  int64 \n",
      " 46  feat_46  61878 non-null  int64 \n",
      " 47  feat_47  61878 non-null  int64 \n",
      " 48  feat_48  61878 non-null  int64 \n",
      " 49  feat_49  61878 non-null  int64 \n",
      " 50  feat_50  61878 non-null  int64 \n",
      " 51  feat_51  61878 non-null  int64 \n",
      " 52  feat_52  61878 non-null  int64 \n",
      " 53  feat_53  61878 non-null  int64 \n",
      " 54  feat_54  61878 non-null  int64 \n",
      " 55  feat_55  61878 non-null  int64 \n",
      " 56  feat_56  61878 non-null  int64 \n",
      " 57  feat_57  61878 non-null  int64 \n",
      " 58  feat_58  61878 non-null  int64 \n",
      " 59  feat_59  61878 non-null  int64 \n",
      " 60  feat_60  61878 non-null  int64 \n",
      " 61  feat_61  61878 non-null  int64 \n",
      " 62  feat_62  61878 non-null  int64 \n",
      " 63  feat_63  61878 non-null  int64 \n",
      " 64  feat_64  61878 non-null  int64 \n",
      " 65  feat_65  61878 non-null  int64 \n",
      " 66  feat_66  61878 non-null  int64 \n",
      " 67  feat_67  61878 non-null  int64 \n",
      " 68  feat_68  61878 non-null  int64 \n",
      " 69  feat_69  61878 non-null  int64 \n",
      " 70  feat_70  61878 non-null  int64 \n",
      " 71  feat_71  61878 non-null  int64 \n",
      " 72  feat_72  61878 non-null  int64 \n",
      " 73  feat_73  61878 non-null  int64 \n",
      " 74  feat_74  61878 non-null  int64 \n",
      " 75  feat_75  61878 non-null  int64 \n",
      " 76  feat_76  61878 non-null  int64 \n",
      " 77  feat_77  61878 non-null  int64 \n",
      " 78  feat_78  61878 non-null  int64 \n",
      " 79  feat_79  61878 non-null  int64 \n",
      " 80  feat_80  61878 non-null  int64 \n",
      " 81  feat_81  61878 non-null  int64 \n",
      " 82  feat_82  61878 non-null  int64 \n",
      " 83  feat_83  61878 non-null  int64 \n",
      " 84  feat_84  61878 non-null  int64 \n",
      " 85  feat_85  61878 non-null  int64 \n",
      " 86  feat_86  61878 non-null  int64 \n",
      " 87  feat_87  61878 non-null  int64 \n",
      " 88  feat_88  61878 non-null  int64 \n",
      " 89  feat_89  61878 non-null  int64 \n",
      " 90  feat_90  61878 non-null  int64 \n",
      " 91  feat_91  61878 non-null  int64 \n",
      " 92  feat_92  61878 non-null  int64 \n",
      " 93  feat_93  61878 non-null  int64 \n",
      " 94  target   61878 non-null  object\n",
      "dtypes: int64(94), object(1)\n",
      "memory usage: 44.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         0\n",
       "feat_1     0\n",
       "feat_2     0\n",
       "feat_3     0\n",
       "feat_4     0\n",
       "          ..\n",
       "feat_90    0\n",
       "feat_91    0\n",
       "feat_92    0\n",
       "feat_93    0\n",
       "target     0\n",
       "Length: 95, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect Duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at all the histograms, you can tell that a lot of the data are zero-inflated, so most of the variables contain mostly zeros and then some higher values here and there. No normality, but for most machine learning techniques this is not an issue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there are so many zeroes, most values above zero will seem to be outliers. The safe decision for this data is to not delete any outliers and see what happens. With many 0s, sparse data is available and high values may be super informative. Moreover, without having any intuitive meaning for each of the features, we don't know if a value of ~260 is actually an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering and selection with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the correlation structure of your features using a [heatmap](https://seaborn.pydata.org/generated/seaborn.heatmap.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use PCA to select a number of features in a way that you still keep 80% of your explained variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X and y\n",
    "X = df.drop(['target'], axis=1)\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Principal Components = 49\n"
     ]
    }
   ],
   "source": [
    "# Mean\n",
    "X_mean = X.mean()\n",
    " \n",
    "# Standard deviation\n",
    "X_std = X.std()\n",
    " \n",
    "# Standardization\n",
    "Z = (X - X_mean) / X_std\n",
    "\n",
    "# Compute covariance matrix\n",
    "c = Z.cov()\n",
    "\n",
    "# Compute eigenvectors and eigenvalues\n",
    "eigenvalues, eigenvectors = np.linalg.eig(c)\n",
    "\n",
    "# Sort the eigenvalues and the corresponding eigenvectors in descending order\n",
    "# Index the eigenvalues in descending order \n",
    "idx = eigenvalues.argsort()[::-1]\n",
    "# Sort the eigenvalues in descending order \n",
    "eigenvalues = eigenvalues[idx]\n",
    "# sort the corresponding eigenvectors accordingly\n",
    "eigenvectors = eigenvectors[:,idx]\n",
    "\n",
    "# Compute explained variance of the eigenvalues\n",
    "explained_var = np.cumsum(eigenvalues) / np.sum(eigenvalues)\n",
    "\n",
    "# Determine the number of principal components \n",
    "# with an explained variance of atleast 80%\n",
    "n_components = np.argmax(explained_var >= 0.80) + 1\n",
    "\n",
    "# print number of principal components\n",
    "print(\"Number of Principal Components =\", n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>...</th>\n",
       "      <th>PC40</th>\n",
       "      <th>PC41</th>\n",
       "      <th>PC42</th>\n",
       "      <th>PC43</th>\n",
       "      <th>PC44</th>\n",
       "      <th>PC45</th>\n",
       "      <th>PC46</th>\n",
       "      <th>PC47</th>\n",
       "      <th>PC48</th>\n",
       "      <th>PC49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.683548</td>\n",
       "      <td>-1.456507</td>\n",
       "      <td>1.411944</td>\n",
       "      <td>-2.680561</td>\n",
       "      <td>-1.613445</td>\n",
       "      <td>-3.989781</td>\n",
       "      <td>-2.832998</td>\n",
       "      <td>-2.918754</td>\n",
       "      <td>-2.510902</td>\n",
       "      <td>-0.760803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.818986</td>\n",
       "      <td>-0.494317</td>\n",
       "      <td>1.176411</td>\n",
       "      <td>-0.641635</td>\n",
       "      <td>-1.096102</td>\n",
       "      <td>-0.155344</td>\n",
       "      <td>1.346502</td>\n",
       "      <td>-0.481683</td>\n",
       "      <td>-0.214463</td>\n",
       "      <td>0.246286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.645988</td>\n",
       "      <td>-1.893243</td>\n",
       "      <td>-0.276866</td>\n",
       "      <td>3.213357</td>\n",
       "      <td>-3.256368</td>\n",
       "      <td>-1.145315</td>\n",
       "      <td>-1.993133</td>\n",
       "      <td>-0.244933</td>\n",
       "      <td>0.778022</td>\n",
       "      <td>-0.025340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019169</td>\n",
       "      <td>-0.318193</td>\n",
       "      <td>-0.085530</td>\n",
       "      <td>0.760190</td>\n",
       "      <td>-0.161854</td>\n",
       "      <td>0.253835</td>\n",
       "      <td>0.236596</td>\n",
       "      <td>-0.225338</td>\n",
       "      <td>0.361819</td>\n",
       "      <td>0.573120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.881297</td>\n",
       "      <td>-3.111402</td>\n",
       "      <td>0.167103</td>\n",
       "      <td>-0.358598</td>\n",
       "      <td>-2.231775</td>\n",
       "      <td>-2.001617</td>\n",
       "      <td>-1.724631</td>\n",
       "      <td>-2.017783</td>\n",
       "      <td>0.086283</td>\n",
       "      <td>1.111060</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024723</td>\n",
       "      <td>0.269060</td>\n",
       "      <td>0.036751</td>\n",
       "      <td>0.044180</td>\n",
       "      <td>-0.777383</td>\n",
       "      <td>-0.249647</td>\n",
       "      <td>0.117856</td>\n",
       "      <td>-1.058864</td>\n",
       "      <td>0.594294</td>\n",
       "      <td>1.496537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.354253</td>\n",
       "      <td>-0.266834</td>\n",
       "      <td>5.140063</td>\n",
       "      <td>-2.754794</td>\n",
       "      <td>-1.604268</td>\n",
       "      <td>-0.389002</td>\n",
       "      <td>-1.379860</td>\n",
       "      <td>1.973593</td>\n",
       "      <td>0.624973</td>\n",
       "      <td>0.420288</td>\n",
       "      <td>...</td>\n",
       "      <td>9.027724</td>\n",
       "      <td>-4.967802</td>\n",
       "      <td>0.054585</td>\n",
       "      <td>1.404898</td>\n",
       "      <td>-8.510237</td>\n",
       "      <td>-3.669086</td>\n",
       "      <td>1.854414</td>\n",
       "      <td>-2.160291</td>\n",
       "      <td>-1.538034</td>\n",
       "      <td>3.585226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.948446</td>\n",
       "      <td>-1.601106</td>\n",
       "      <td>-2.180337</td>\n",
       "      <td>1.959822</td>\n",
       "      <td>-2.808223</td>\n",
       "      <td>-1.467113</td>\n",
       "      <td>-2.486020</td>\n",
       "      <td>-0.599538</td>\n",
       "      <td>-0.254935</td>\n",
       "      <td>-0.260538</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139382</td>\n",
       "      <td>0.379848</td>\n",
       "      <td>-0.117925</td>\n",
       "      <td>0.307644</td>\n",
       "      <td>-0.590505</td>\n",
       "      <td>0.622268</td>\n",
       "      <td>0.877822</td>\n",
       "      <td>0.032856</td>\n",
       "      <td>0.501068</td>\n",
       "      <td>0.350772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61873</th>\n",
       "      <td>2.246453</td>\n",
       "      <td>3.820398</td>\n",
       "      <td>5.943894</td>\n",
       "      <td>-7.373531</td>\n",
       "      <td>14.608052</td>\n",
       "      <td>-0.915350</td>\n",
       "      <td>1.937525</td>\n",
       "      <td>-7.596933</td>\n",
       "      <td>-6.158874</td>\n",
       "      <td>-3.300357</td>\n",
       "      <td>...</td>\n",
       "      <td>8.131801</td>\n",
       "      <td>8.059145</td>\n",
       "      <td>12.713684</td>\n",
       "      <td>0.813836</td>\n",
       "      <td>-0.340855</td>\n",
       "      <td>3.637284</td>\n",
       "      <td>2.835560</td>\n",
       "      <td>6.354039</td>\n",
       "      <td>-6.612726</td>\n",
       "      <td>-2.776392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61874</th>\n",
       "      <td>-1.929256</td>\n",
       "      <td>-3.265102</td>\n",
       "      <td>0.279949</td>\n",
       "      <td>-0.639577</td>\n",
       "      <td>-0.187086</td>\n",
       "      <td>-2.951185</td>\n",
       "      <td>-0.059637</td>\n",
       "      <td>-2.487794</td>\n",
       "      <td>-0.118592</td>\n",
       "      <td>0.763973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580190</td>\n",
       "      <td>0.010070</td>\n",
       "      <td>1.107310</td>\n",
       "      <td>0.276667</td>\n",
       "      <td>-1.174522</td>\n",
       "      <td>-0.100865</td>\n",
       "      <td>-1.325581</td>\n",
       "      <td>0.338815</td>\n",
       "      <td>-1.144150</td>\n",
       "      <td>1.643478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61875</th>\n",
       "      <td>4.241452</td>\n",
       "      <td>-7.466896</td>\n",
       "      <td>6.809563</td>\n",
       "      <td>-8.615352</td>\n",
       "      <td>2.796913</td>\n",
       "      <td>-4.236099</td>\n",
       "      <td>0.372613</td>\n",
       "      <td>-8.487954</td>\n",
       "      <td>0.299560</td>\n",
       "      <td>5.484483</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.572760</td>\n",
       "      <td>-0.132036</td>\n",
       "      <td>-1.820427</td>\n",
       "      <td>0.847127</td>\n",
       "      <td>-0.051036</td>\n",
       "      <td>1.891836</td>\n",
       "      <td>1.096517</td>\n",
       "      <td>-0.141154</td>\n",
       "      <td>-0.666354</td>\n",
       "      <td>-1.129437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61876</th>\n",
       "      <td>-0.347051</td>\n",
       "      <td>-2.212910</td>\n",
       "      <td>1.389312</td>\n",
       "      <td>-2.284562</td>\n",
       "      <td>-0.371693</td>\n",
       "      <td>-2.311001</td>\n",
       "      <td>-1.747018</td>\n",
       "      <td>-3.067846</td>\n",
       "      <td>-0.440319</td>\n",
       "      <td>1.020332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850393</td>\n",
       "      <td>1.538233</td>\n",
       "      <td>1.071178</td>\n",
       "      <td>-0.167398</td>\n",
       "      <td>-1.649595</td>\n",
       "      <td>0.438646</td>\n",
       "      <td>-3.176340</td>\n",
       "      <td>1.019229</td>\n",
       "      <td>-0.836431</td>\n",
       "      <td>-1.029299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61877</th>\n",
       "      <td>1.502288</td>\n",
       "      <td>-0.681675</td>\n",
       "      <td>3.494536</td>\n",
       "      <td>-4.401209</td>\n",
       "      <td>1.228140</td>\n",
       "      <td>-2.876485</td>\n",
       "      <td>-2.112371</td>\n",
       "      <td>-4.040629</td>\n",
       "      <td>-0.136830</td>\n",
       "      <td>1.693349</td>\n",
       "      <td>...</td>\n",
       "      <td>1.827495</td>\n",
       "      <td>1.730254</td>\n",
       "      <td>1.245869</td>\n",
       "      <td>-0.532066</td>\n",
       "      <td>-0.920731</td>\n",
       "      <td>-0.408214</td>\n",
       "      <td>1.099411</td>\n",
       "      <td>1.809342</td>\n",
       "      <td>-1.803757</td>\n",
       "      <td>0.430778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61878 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            PC1       PC2       PC3       PC4        PC5       PC6       PC7  \\\n",
       "0      0.683548 -1.456507  1.411944 -2.680561  -1.613445 -3.989781 -2.832998   \n",
       "1     -2.645988 -1.893243 -0.276866  3.213357  -3.256368 -1.145315 -1.993133   \n",
       "2     -1.881297 -3.111402  0.167103 -0.358598  -2.231775 -2.001617 -1.724631   \n",
       "3      5.354253 -0.266834  5.140063 -2.754794  -1.604268 -0.389002 -1.379860   \n",
       "4     -2.948446 -1.601106 -2.180337  1.959822  -2.808223 -1.467113 -2.486020   \n",
       "...         ...       ...       ...       ...        ...       ...       ...   \n",
       "61873  2.246453  3.820398  5.943894 -7.373531  14.608052 -0.915350  1.937525   \n",
       "61874 -1.929256 -3.265102  0.279949 -0.639577  -0.187086 -2.951185 -0.059637   \n",
       "61875  4.241452 -7.466896  6.809563 -8.615352   2.796913 -4.236099  0.372613   \n",
       "61876 -0.347051 -2.212910  1.389312 -2.284562  -0.371693 -2.311001 -1.747018   \n",
       "61877  1.502288 -0.681675  3.494536 -4.401209   1.228140 -2.876485 -2.112371   \n",
       "\n",
       "            PC8       PC9      PC10  ...      PC40      PC41       PC42  \\\n",
       "0     -2.918754 -2.510902 -0.760803  ...  0.818986 -0.494317   1.176411   \n",
       "1     -0.244933  0.778022 -0.025340  ...  0.019169 -0.318193  -0.085530   \n",
       "2     -2.017783  0.086283  1.111060  ... -0.024723  0.269060   0.036751   \n",
       "3      1.973593  0.624973  0.420288  ...  9.027724 -4.967802   0.054585   \n",
       "4     -0.599538 -0.254935 -0.260538  ... -0.139382  0.379848  -0.117925   \n",
       "...         ...       ...       ...  ...       ...       ...        ...   \n",
       "61873 -7.596933 -6.158874 -3.300357  ...  8.131801  8.059145  12.713684   \n",
       "61874 -2.487794 -0.118592  0.763973  ...  0.580190  0.010070   1.107310   \n",
       "61875 -8.487954  0.299560  5.484483  ... -1.572760 -0.132036  -1.820427   \n",
       "61876 -3.067846 -0.440319  1.020332  ...  0.850393  1.538233   1.071178   \n",
       "61877 -4.040629 -0.136830  1.693349  ...  1.827495  1.730254   1.245869   \n",
       "\n",
       "           PC43      PC44      PC45      PC46      PC47      PC48      PC49  \n",
       "0     -0.641635 -1.096102 -0.155344  1.346502 -0.481683 -0.214463  0.246286  \n",
       "1      0.760190 -0.161854  0.253835  0.236596 -0.225338  0.361819  0.573120  \n",
       "2      0.044180 -0.777383 -0.249647  0.117856 -1.058864  0.594294  1.496537  \n",
       "3      1.404898 -8.510237 -3.669086  1.854414 -2.160291 -1.538034  3.585226  \n",
       "4      0.307644 -0.590505  0.622268  0.877822  0.032856  0.501068  0.350772  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "61873  0.813836 -0.340855  3.637284  2.835560  6.354039 -6.612726 -2.776392  \n",
       "61874  0.276667 -1.174522 -0.100865 -1.325581  0.338815 -1.144150  1.643478  \n",
       "61875  0.847127 -0.051036  1.891836  1.096517 -0.141154 -0.666354 -1.129437  \n",
       "61876 -0.167398 -1.649595  0.438646 -3.176340  1.019229 -0.836431 -1.029299  \n",
       "61877 -0.532066 -0.920731 -0.408214  1.099411  1.809342 -1.803757  0.430778  \n",
       "\n",
       "[61878 rows x 49 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe of the principal components\n",
    "\n",
    "# Import PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Instantiate PCA\n",
    "n_components = 49\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "# Fit PCA\n",
    "principalComponents = pca.fit_transform(X)\n",
    "\n",
    "df_pca = pd.DataFrame(principalComponents,\n",
    "                       columns=['PC{}'.\n",
    "                       format(i+1)\n",
    "                        for i in range(n_components)])\n",
    "df_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a train-test split with a test size of 40%\n",
    "\n",
    "This is a relatively big training set, so you can assign 40% to the test set. Set the `random_state` to 42. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the PCA dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_pca, y, \n",
    "                                                    test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your baseline model *in a pipeline setting*. In the pipeline: \n",
    "\n",
    "- Your first step will be to scale your features down to the number of features that ensure you keep just 80% of your explained variance (which we saw before)\n",
    "- Your second step will be to build a basic logistic regression model \n",
    "\n",
    "Make sure to fit the model using the training set and test the result by obtaining the accuracy using the test set. Set the `random_state` to 123. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a pipeline consisting of a linear SVM, a simple decision tree, and a simple random forest classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the above, but now create three different pipelines:\n",
    "- One for a standard linear SVM\n",
    "- One for a default decision tree\n",
    "- One for a random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class_2    9666\n",
       "Class_6    8441\n",
       "Class_8    5094\n",
       "Class_3    4863\n",
       "Class_9    2921\n",
       "Class_7    1732\n",
       "Class_5    1654\n",
       "Class_4    1621\n",
       "Class_1    1134\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of target classes\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;ss&#x27;, StandardScaler()),\n",
       "                (&#x27;svc&#x27;, SVC(kernel=&#x27;linear&#x27;, random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;ss&#x27;, StandardScaler()),\n",
       "                (&#x27;svc&#x27;, SVC(kernel=&#x27;linear&#x27;, random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('ss', StandardScaler()),\n",
       "                ('svc', SVC(kernel='linear', random_state=42))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Standard Linear SVM pipeline\n",
    "pipe_svm = Pipeline([('ss', StandardScaler()), \n",
    "                    ('svc', SVC(kernel='linear', random_state=42))])\n",
    "\n",
    "# Fit the pipeline on training set\n",
    "pipe_svm.fit(X_train, y_train)\n",
    "\n",
    "# ⏰ This cell may take several minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7584033613445378"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_svm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy score 0.7584033613445378\n",
      "Overall precision score 0.7587977183724836\n",
      "Overall recall score 0.7584033613445378\n",
      "Overall F1-score 0.7290679512420039\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "y_pred = pipe_svm.predict(X_test)\n",
    "print(\"Overall accuracy score\", accuracy_score(y_test, y_pred))\n",
    "print(\"Overall precision score\", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Overall recall score\", recall_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Overall F1-score\", f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline with grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct two pipelines with grid search:\n",
    "- one for random forests - try to have around 40 different models\n",
    "- one for the AdaBoost algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest pipeline with grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here \n",
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# ⏰ This cell may take a long time to run!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your grid search object along with `.cv_results` to get the full result overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# ⏰ This cell may take several minutes to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your grid search object along with `.cv_results` to get the full result overview: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level-up (Optional): SVM pipeline with grid search \n",
    "\n",
    "As extra level-up work, construct a pipeline with grid search for support vector machines. \n",
    "* Make sure your grid isn't too big. You'll see it takes quite a while to fit SVMs with non-linear kernel functions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# ⏰ This cell may take a very long time to run!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your grid search object along with `.cv_results` to get the full result overview: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "\n",
    "Note that this solution is only one of many options. The results in the Random Forest and AdaBoost models show that there is a lot of improvement possible by tuning the hyperparameters further, so make sure to explore this yourself!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "Great! You've gotten a lot of practice in using PCA in pipelines. What algorithm would you choose and why?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
